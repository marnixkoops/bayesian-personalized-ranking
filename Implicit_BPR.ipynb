{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Personalized Ranking (BPR)\n",
    "On user product browsing data (implicit feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "tf.__version__  # needs TF 1.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data\n",
    "DATA_PATH1 = (\n",
    "    \"/Users/marnix.koops/Projects/marnix-single-flow-rnn/data/ga_product_sequence_20191013.csv\"\n",
    ")\n",
    "DATA_PATH2 = (\n",
    "    \"/Users/marnix.koops/Projects/marnix-single-flow-rnn/data/ga_product_sequence_20191020.csv\"\n",
    ")\n",
    "DATA_PATH3 = (\n",
    "    \"/Users/marnix.koops/Projects/marnix-single-flow-rnn/data/ga_product_sequence_20191027.csv\"\n",
    ")\n",
    "DATA_PATH4 = (\n",
    "    \"/Users/marnix.koops/Projects/marnix-single-flow-rnn/data/ga_product_sequence_20191103.csv\"\n",
    ")\n",
    "\n",
    "sequence_df = pd.read_csv(DATA_PATH1)\n",
    "sequence_df2 = pd.read_csv(DATA_PATH2)\n",
    "sequence_df3 = pd.read_csv(DATA_PATH3)\n",
    "sequence_df4 = pd.read_csv(DATA_PATH4)\n",
    "df = sequence_df2.append(sequence_df2).append(sequence_df3).append(sequence_df4)\n",
    "del sequence_df, sequence_df2, sequence_df3, sequence_df4\n",
    "df = df.drop_duplicates(keep=\"first\")  # also checks for visit_date + id\n",
    "product_map_df = pd.read_csv(\n",
    "    \"/Users/marnix.koops/Projects/marnix-single-flow-rnn/data/product_mapping.csv\"\n",
    ")\n",
    "product_map_df[\"product_id\"] = product_map_df[\"product_id\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coolblue_cookie_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>product_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cc49e3c31c05c88f1a1ec9fbc15fa8fe</td>\n",
       "      <td>20191014</td>\n",
       "      <td>774942,172298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ce5eddfdea862ff938e164e2221d2b67</td>\n",
       "      <td>20191014</td>\n",
       "      <td>832354,184434,184388,184434,345944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5e785c1dee51a58e6a6bc717acbe6bc1</td>\n",
       "      <td>20191014</td>\n",
       "      <td>818807,818807,818807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7249834b3096fada61aebe16921cd107</td>\n",
       "      <td>20191014</td>\n",
       "      <td>822691,795775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66a439e1237bd01c20d3ca781c3db0e5</td>\n",
       "      <td>20191014</td>\n",
       "      <td>833416,838406,838391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 coolblue_cookie_id  visit_date  \\\n",
       "0  cc49e3c31c05c88f1a1ec9fbc15fa8fe    20191014   \n",
       "1  ce5eddfdea862ff938e164e2221d2b67    20191014   \n",
       "2  5e785c1dee51a58e6a6bc717acbe6bc1    20191014   \n",
       "3  7249834b3096fada61aebe16921cd107    20191014   \n",
       "4  66a439e1237bd01c20d3ca781c3db0e5    20191014   \n",
       "\n",
       "                     product_sequence  \n",
       "0                       774942,172298  \n",
       "1  832354,184434,184388,184434,345944  \n",
       "2                818807,818807,818807  \n",
       "3                       822691,795775  \n",
       "4                833416,838406,838391  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_type_name</th>\n",
       "      <th>product_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>MP3 spelers</td>\n",
       "      <td>Samsung Yepp 64 Mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>MP3 spelers</td>\n",
       "      <td>JazPiper 32 MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>MP3 spelers</td>\n",
       "      <td>JazPiper 64 MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>MP3 spelers</td>\n",
       "      <td>Diamond Rio 300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>MP3 spelers</td>\n",
       "      <td>Diamond Rio 500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  product_id product_type_name        product_name\n",
       "0      10000       MP3 spelers  Samsung Yepp 64 Mb\n",
       "1      10001       MP3 spelers      JazPiper 32 MB\n",
       "2      10002       MP3 spelers      JazPiper 64 MB\n",
       "3      10003       MP3 spelers     Diamond Rio 300\n",
       "4      10004       MP3 spelers     Diamond Rio 500"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_map_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train-test datasets\n",
    "train_partition_final_row = int(0.8 * len(df))\n",
    "df_test = df[train_partition_final_row:]\n",
    "df = df[:train_partition_final_row].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coolblue_cookie_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>clicks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000013487f8f8fcfbe04fa35b1a81a7</td>\n",
       "      <td>698275</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000013487f8f8fcfbe04fa35b1a81a7</td>\n",
       "      <td>823571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000005a934827a753dd3685f63de15ce</td>\n",
       "      <td>505656</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000005a934827a753dd3685f63de15ce</td>\n",
       "      <td>817952</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000005a934827a753dd3685f63de15ce</td>\n",
       "      <td>822105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 coolblue_cookie_id product_id  clicks\n",
       "0  0000013487f8f8fcfbe04fa35b1a81a7     698275       5\n",
       "1  0000013487f8f8fcfbe04fa35b1a81a7     823571       1\n",
       "2  000005a934827a753dd3685f63de15ce     505656       1\n",
       "3  000005a934827a753dd3685f63de15ce     817952       1\n",
       "4  000005a934827a753dd3685f63de15ce     822105       1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform to user/product/count (loses sequence order information)\n",
    "df = pd.DataFrame(\n",
    "    df[\"product_sequence\"].str.split(\",\").tolist(), index=df[\"coolblue_cookie_id\"]\n",
    ").stack()\n",
    "df = df.reset_index([0, \"coolblue_cookie_id\"])\n",
    "df.columns = [\"coolblue_cookie_id\", \"product_id\"]\n",
    "df = df.groupby(df.columns.tolist(), as_index=False).size()\n",
    "df = df.reset_index(drop=False)\n",
    "df.columns = [\"coolblue_cookie_id\", \"product_id\", \"clicks\"]\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert product_ids names into numerical IDs\n",
    "df[\"coolblue_cookie_token\"] = df[\"coolblue_cookie_id\"].astype(\"category\").cat.codes\n",
    "df[\"product_token\"] = df[\"product_id\"].astype(\"category\").cat.codes\n",
    "\n",
    "# Create a lookup frame so we can get the product_id\n",
    "# names back in readable form later.\n",
    "item_lookup = df[[\"product_token\", \"product_id\"]].drop_duplicates()\n",
    "item_lookup[\"product_token\"] = item_lookup.product_token.astype(str)\n",
    "\n",
    "# We drop our old coolblue_cookie_id and product_id columns\n",
    "df = df.drop([\"coolblue_cookie_id\", \"product_id\"], axis=1)\n",
    "\n",
    "# Drop any rows with 0 clicks\n",
    "df = df.loc[df.clicks != 0]\n",
    "\n",
    "# Create lists of all coolblue_cookie_ids, product_ids and clicks\n",
    "coolblue_cookie_ids = list(np.sort(df.coolblue_cookie_token.unique()))\n",
    "product_ids = list(np.sort(df.product_token.unique()))\n",
    "clicks = list(df.clicks)\n",
    "\n",
    "# Get the rows and columns for our new matrix\n",
    "rows = df.coolblue_cookie_token.astype(float)\n",
    "cols = df.product_token.astype(float)\n",
    "\n",
    "# Contruct a sparse matrix for our coolblue_cookie_ids and items containing number of clicks\n",
    "data_sparse = sp.csr_matrix(\n",
    "    (clicks, (rows, cols)), shape=(len(coolblue_cookie_ids), len(product_ids))\n",
    ")\n",
    "\n",
    "\n",
    "# Get the values of our matrix as a list of coolblue_cookie_id ids\n",
    "# and item ids. Note that our litsts have the same length\n",
    "# as each coolblue_cookie_id id repeats one time for each played product_id.\n",
    "uids, iids = data_sparse.nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------\n",
    "# HYPERPARAMS\n",
    "# -------------\n",
    "\n",
    "epochs = 48\n",
    "batches = 64\n",
    "num_factors = 64  # Number of latent features\n",
    "\n",
    "# Independent lambda regularization values\n",
    "# for coolblue_cookie_id, items and bias.\n",
    "lambda_coolblue_cookie_id = 0.0000001\n",
    "lambda_item = 0.0000001\n",
    "lambda_bias = 0.0000001\n",
    "\n",
    "# Our learning rate\n",
    "lr = 0.005\n",
    "\n",
    "# How many (u,i,j) triplets we sample for each batch\n",
    "samples = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# TENSORFLOW GRAPH\n",
    "# -------------------------\n",
    "\n",
    "t_train = time.time()  # start timer for training\n",
    "\n",
    "\n",
    "# Set up our Tensorflow graph\n",
    "graph = tf.Graph()\n",
    "\n",
    "\n",
    "def init_variable(size, dim, name=None):\n",
    "    \"\"\"\n",
    "    Helper function to initialize a new variable with\n",
    "    uniform random values.\n",
    "    \"\"\"\n",
    "    std = np.sqrt(2 / dim)\n",
    "    return tf.Variable(tf.random_uniform([size, dim], -std, std), name=name)\n",
    "\n",
    "\n",
    "def embed(inputs, size, dim, name=None):\n",
    "    \"\"\"\n",
    "    Helper function to get a Tensorflow variable and create\n",
    "    an embedding lookup to map our coolblue_cookie_id and item\n",
    "    indices to vectors.\n",
    "    \"\"\"\n",
    "    emb = init_variable(size, dim, name)\n",
    "    return tf.nn.embedding_lookup(emb, inputs)\n",
    "\n",
    "\n",
    "def get_variable(graph, session, name):\n",
    "    \"\"\"\n",
    "    Helper function to get the value of a\n",
    "    Tensorflow variable by name.\n",
    "    \"\"\"\n",
    "    v = graph.get_operation_by_name(name)\n",
    "    v = v.values()[0]\n",
    "    v = v.eval(session=session)\n",
    "    return v\n",
    "\n",
    "\n",
    "with graph.as_default():\n",
    "    \"\"\"\n",
    "    Loss function:\n",
    "    -SUM ln σ(xui - xuj) + λ(w1)**2 + λ(w2)**2 + λ(w3)**2 ...\n",
    "    ln = the natural log\n",
    "    σ(xuij) = the sigmoid function of xuij.\n",
    "    λ = lambda regularization value.\n",
    "    ||W||**2 = the squared L2 norm of our model parameters.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Input into our model, in this case our coolblue_cookie_id (u),\n",
    "    # known item (i) an unknown item (i) triplets.\n",
    "    u = tf.placeholder(tf.int32, shape=(None, 1))\n",
    "    i = tf.placeholder(tf.int32, shape=(None, 1))\n",
    "    j = tf.placeholder(tf.int32, shape=(None, 1))\n",
    "\n",
    "    # coolblue_cookie_id feature embedding\n",
    "    u_factors = embed(\n",
    "        u, len(coolblue_cookie_ids), num_factors, \"coolblue_cookie_id_factors\"\n",
    "    )  # U matrix\n",
    "\n",
    "    # Known and unknown item embeddings\n",
    "    item_factors = init_variable(len(product_ids), num_factors, \"item_factors\")  # V matrix\n",
    "    i_factors = tf.nn.embedding_lookup(item_factors, i)\n",
    "    j_factors = tf.nn.embedding_lookup(item_factors, j)\n",
    "\n",
    "    # i and j bias embeddings.\n",
    "    item_bias = init_variable(len(product_ids), 1, \"item_bias\")\n",
    "    i_bias = tf.nn.embedding_lookup(item_bias, i)\n",
    "    i_bias = tf.reshape(i_bias, [-1, 1])\n",
    "    j_bias = tf.nn.embedding_lookup(item_bias, j)\n",
    "    j_bias = tf.reshape(j_bias, [-1, 1])\n",
    "\n",
    "    # Calculate the dot product + bias for known and unknown\n",
    "    # item to get xui and xuj.\n",
    "    xui = i_bias + tf.reduce_sum(u_factors * i_factors, axis=2)\n",
    "    xuj = j_bias + tf.reduce_sum(u_factors * j_factors, axis=2)\n",
    "\n",
    "    # We calculate xuij.\n",
    "    xuij = xui - xuj\n",
    "\n",
    "    # Calculate the mean AUC (area under curve).\n",
    "    # if xuij is greater than 0, that means that\n",
    "    # xui is greater than xuj (and thats what we want).\n",
    "    u_auc = tf.reduce_mean(tf.to_float(xuij > 0))\n",
    "\n",
    "    # Output the AUC value to tensorboard for monitoring.\n",
    "    tf.summary.scalar(\"auc\", u_auc)\n",
    "\n",
    "    # Calculate the squared L2 norm ||W||**2 multiplied by λ.\n",
    "    l2_norm = tf.add_n(\n",
    "        [\n",
    "            lambda_coolblue_cookie_id * tf.reduce_sum(tf.multiply(u_factors, u_factors)),\n",
    "            lambda_item * tf.reduce_sum(tf.multiply(i_factors, i_factors)),\n",
    "            lambda_item * tf.reduce_sum(tf.multiply(j_factors, j_factors)),\n",
    "            lambda_bias * tf.reduce_sum(tf.multiply(i_bias, i_bias)),\n",
    "            lambda_bias * tf.reduce_sum(tf.multiply(j_bias, j_bias)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Calculate the loss as ||W||**2 - ln σ(Xuij)\n",
    "    # loss = l2_norm - tf.reduce_mean(tf.log(tf.sigmoid(xuij)))\n",
    "    loss = -tf.reduce_mean(tf.log(tf.sigmoid(xuij))) + l2_norm\n",
    "\n",
    "    # Train using the Adam optimizer to minimize\n",
    "    # our loss function.\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "    step = opt.minimize(loss)\n",
    "\n",
    "    # Initialize all tensorflow variables.\n",
    "    init = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------\n",
    "# GRAPH EXECUTION\n",
    "# ------------------\n",
    "\n",
    "# Run the session.\n",
    "session = tf.Session(config=None, graph=graph)\n",
    "session.run(init)\n",
    "\n",
    "# This has noting to do with tensorflow but gives\n",
    "# us a nice progress bar for the training.\n",
    "progress = tqdm(total=batches * epochs)\n",
    "\n",
    "for _ in range(epochs):\n",
    "    for _ in range(batches):\n",
    "\n",
    "        # We want to sample one known and one unknown\n",
    "        # item for each coolblue_cookie_id.\n",
    "\n",
    "        # First we sample 15000 uniform indices.\n",
    "        idx = np.random.randint(low=0, high=len(uids), size=samples)\n",
    "\n",
    "        # We then grab the coolblue_cookie_ids matching those indices.\n",
    "        batch_u = uids[idx].reshape(-1, 1)\n",
    "\n",
    "        # Then the known items for those coolblue_cookie_ids.\n",
    "        batch_i = iids[idx].reshape(-1, 1)\n",
    "\n",
    "        # Lastly we randomly sample one unknown item for each coolblue_cookie_id.\n",
    "        batch_j = np.random.randint(low=0, high=len(product_ids), size=(samples, 1), dtype=\"int32\")\n",
    "\n",
    "        # Feed our coolblue_cookie_ids, known and unknown items to\n",
    "        # our tensorflow graph.\n",
    "        feed_dict = {u: batch_u, i: batch_i, j: batch_j}\n",
    "\n",
    "        # We run the session.\n",
    "        _, l, auc = session.run([step, loss, u_auc], feed_dict)\n",
    "\n",
    "    progress.update(batches)\n",
    "    progress.set_description(\"Loss: %.3f | AUC: %.3f\" % (l, auc))\n",
    "\n",
    "progress.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# FIND SIMILAR product_idS\n",
    "# -----------------------\n",
    "\n",
    "\n",
    "def find_similar_product_ids(product_id=None, num_items=10):\n",
    "    \"\"\"Find product_ids similar to an product_id.\n",
    "    Args:\n",
    "        product_id (str): The name of the product_id we want to find similar product_ids for\n",
    "        num_items (int): How many similar product_ids we want to return.\n",
    "    Returns:\n",
    "        similar (pandas.DataFrame): DataFrame with num_items product_id names and scores\n",
    "    \"\"\"\n",
    "\n",
    "    # Grab our coolblue_cookie_id matrix U\n",
    "    coolblue_cookie_id_vecs = get_variable(graph, session, \"coolblue_cookie_id_factors\")\n",
    "\n",
    "    # Grab our Item matrix V\n",
    "    item_vecs = get_variable(graph, session, \"item_factors\")\n",
    "\n",
    "    # Grab our item bias\n",
    "    item_bi = get_variable(graph, session, \"item_bias\").reshape(-1)\n",
    "\n",
    "    # Get the item id for Lady GaGa\n",
    "    item_id = int(item_lookup[item_lookup.product_id == product_id][\"product_token\"])\n",
    "\n",
    "    # Get the item vector for our item_id and transpose it.\n",
    "    item_vec = item_vecs[item_id].T\n",
    "\n",
    "    # Calculate the similarity between Lady GaGa and all other product_ids\n",
    "    # by multiplying the item vector with our item_matrix\n",
    "    scores = np.add(item_vecs.dot(item_vec), item_bi).reshape(1, -1)[0]\n",
    "\n",
    "    # Get the indices for the top 10 scores\n",
    "    top_10 = np.argsort(scores)[::-1][:num_items]\n",
    "\n",
    "    # We then use our lookup table to grab the names of these indices\n",
    "    # and add it along with its score to a pandas dataframe.\n",
    "    product_ids, product_id_scores = [], []\n",
    "\n",
    "    for idx in top_10:\n",
    "        product_ids.append(\n",
    "            item_lookup.product_id.loc[item_lookup.product_token == str(idx)].iloc[0]\n",
    "        )\n",
    "        product_id_scores.append(scores[idx])\n",
    "\n",
    "    similar = pd.DataFrame({\"product_id\": product_ids, \"score\": product_id_scores})\n",
    "    similar[\"product_name\"] = similar[\"product_id\"].map(\n",
    "        dict(zip(product_map_df[\"product_id\"], product_map_df[\"product_name\"]))\n",
    "    )\n",
    "    similar[\"product_type_name\"] = similar[\"product_id\"].map(\n",
    "        dict(zip(product_map_df[\"product_id\"], product_map_df[\"product_type_name\"]))\n",
    "    )\n",
    "\n",
    "    return similar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_recommendation(coolblue_cookie_token=None, num_items=10):\n",
    "    \"\"\"Recommend items for a given coolblue_cookie_id given a trained model\n",
    "    Args:\n",
    "        coolblue_cookie_token (int): The id of the coolblue_cookie_id we want to create recommendations for.\n",
    "        num_items (int): How many recommendations we want to return.\n",
    "    Returns:\n",
    "        recommendations (pandas.DataFrame): DataFrame with num_items product_id names and scores\n",
    "    \"\"\"\n",
    "\n",
    "    # Grab our coolblue_cookie_id matrix U\n",
    "    coolblue_cookie_id_vecs = get_variable(graph, session, \"coolblue_cookie_id_factors\")\n",
    "\n",
    "    # Grab our item matrix V\n",
    "    item_vecs = get_variable(graph, session, \"item_factors\")\n",
    "\n",
    "    # Grab our item bias\n",
    "    item_bi = get_variable(graph, session, \"item_bias\").reshape(-1)\n",
    "\n",
    "    # Calculate the score for our coolblue_cookie_id for all items.\n",
    "    rec_vector = np.add(coolblue_cookie_id_vecs[coolblue_cookie_token, :].dot(item_vecs.T), item_bi)\n",
    "\n",
    "    # Grab the indices of the top coolblue_cookie_ids\n",
    "    item_idx = np.argsort(rec_vector)[::-1][:num_items]\n",
    "\n",
    "    # Map the indices to product_id names and add to dataframe along with scores.\n",
    "    product_ids, scores = [], []\n",
    "\n",
    "    for idx in item_idx:\n",
    "        product_ids.append(\n",
    "            item_lookup.product_id.loc[item_lookup.product_token == str(idx)].iloc[0]\n",
    "        )\n",
    "        scores.append(rec_vector[idx])\n",
    "\n",
    "    recommendations = pd.DataFrame({\"product_id\": product_ids, \"score\": scores})\n",
    "    recommendations[\"product_name\"] = recommendations[\"product_id\"].map(\n",
    "        dict(zip(product_map_df[\"product_id\"], product_map_df[\"product_name\"]))\n",
    "    )\n",
    "    recommendations[\"product_type_name\"] = recommendations[\"product_id\"].map(\n",
    "        dict(zip(product_map_df[\"product_id\"], product_map_df[\"product_type_name\"]))\n",
    "    )\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(find_similar_product_ids(product_id=\"795117\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(make_recommendation(coolblue_cookie_token=56))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
